# 处理不同的数据类型

* 转换成Spark类型

      使用 lit 函数将原始类型转换为Spark类型

```scala
import org.spark.sql.functions.lit
df.select(lit(5), lit("five"), lit(5.0))
```

```py
# in Python
from pyspark.sql.functions import lit
df.select(lit(5), lit("five"), lit(5.0))
```

* 处理布尔类型

  * 布尔语句由四个要素组成 and or true false
  * 当根据多个条件同时进行过滤时，可以使用 and 或者 or 将多个Boolean表达式连接起来，但是在Spark中，最好是以链接的方式组合起来

```scala
// 在Spark中想通过相等条件进行过滤，应该使用 === 或者  =!= 不于 符号，还可以使用not函数和equalTo方法

import org.spark.sql.functions.col
df.where(col("InvoiceNo").equalTo(536365))
.select("InvoiceNo", "Description")
.show(5, false)

import org.spark.sql.functions.col
df.where(col("InvoiceNo").equalTo(536365))
.select("InvoiceNo", "Description")
.show(5, false)
  ```

```py
# in Python
from pyspark.sql.functions import col
df.where(col("InvoiceNo") != 536365)\
.select("InvoiceNo", "Description")\
.show(5, False)

# 还可以使用字符串形式的谓词表达式
df.where("InvoiceNo = 536365")\
.show(5, False)
df.where("InvoiceNo <> 536365")\
.show(5, False)
```
