# 处理不同的数据类型

* 转换成Spark类型

      使用 lit 函数将原始类型转换为Spark类型

```scala
import org.spark.sql.functions.lit
df.select(lit(5), lit("five"), lit(5.0))
```

```py
# in Python
from pyspark.sql.functions import lit
df.select(lit(5), lit("five"), lit(5.0))
```

* 处理布尔类型

  * 布尔语句由四个要素组成 and or true false
  * 当根据多个条件同时进行过滤时，可以使用 and 或者 or 将多个Boolean表达式连接起来，但是在Spark中，最好是以链接的方式组合起来

```scala
// 在Spark中想通过相等条件进行过滤，应该使用 === 或者  =!= 不于 符号，还可以使用not函数和equalTo方法

import org.spark.sql.functions.col
df.where(col("InvoiceNo").equalTo(536365))
.select("InvoiceNo", "Description")
.show(5, false)

import org.spark.sql.functions.col
df.where(col("InvoiceNo").equalTo(536365))
.select("InvoiceNo", "Description")
.show(5, false)

// 布尔表达式不一定非要在过滤器中使用，想要过滤DataFrame，也可以设定一个Boolean类型的列
val DOTCodeFilter = col("StockCode") === "DOT"
val priceFilter = col("UnitPrice") > 600
val descripFilter = col("Description").contains("POSTAGE")
df.withColumn("isExpensive", DOTCodeFilter.and(priceFilter.or(descripFilter)))
.where("isExpensive")
.select("unitPrice", "isExpensive").show(5)
  ```

```py
# in Python
from pyspark.sql.functions import col
df.where(col("InvoiceNo") != 536365)\
.select("InvoiceNo", "Description")\
.show(5, False)

# 还可以使用字符串形式的谓词表达式
df.where("InvoiceNo = 536365")\
.show(5, False)
df.where("InvoiceNo <> 536365")\
.show(5, False)

# 布尔表达式不一定非要在过滤器中使用，想要过滤DataFrame，也可以设定一个Boolean类型的列

from pyspark.sql.functions import instr
DOTCodeFilter = col("StockCode") == "DOT
priceFilter = col("UnitPrice") > 600
descripFilter = instr(col("Description"), "POSTAGE") >= 1
df.withColumn("isExpensive", DOTCodeFilter & (priceFilter | descripFilter))\
.where("isExpensive")\
.select("unitPrice", "isExpensive").show(5)
```

* 处理数值类型

```scala
// pow 函数对指定列进行幂运算
import org.apache.spark.sql.functions.{expr, pow}
val fabricateQuantity = pow(col("Quantity") * col("UnitPrice"), 2) + 5
df.select(expr("CustomerId"), fabricateQuantity.alias("realQuantity")).show(2)

// round默认会向上取整，bround函数进行向下取整
import org.apache.spark.sql.functions.lit
df.select(round(lit("2.5")), bround(lit("2.5"))).show(2)

// corr 可以计算两列的相关性
df.stat.corr("QUantity", "UnitPrice")
df.select(corr("Quantity", "UnitPrice")).show()
// describe 计算一列或一组列的汇总统计结果，它会计算所有数值型列的计数，平均值，标准差，最小值和最大值
df.describe().show()

// 更多统计函数封装在 StatFunction中，例如approxQuantile
```
```py
# in Python

# pow 函数对指定列进行幂运算
from pyspark.sql.functions import expr, pow
fabricateQuantity = pow(col("Quantity") * col("UnitPrice"), 2) + 5
df.select(expr("CustomerId"), fabricateQuantity.alias("realQuantity")).show(2)
# round默认会向上取整，bround函数进行向下取整
from pyspark.sql.functions import lit, round, bround
df.select(round(lit("2.5")), bround(lit("2.5"))).show(2)

#corr 可以计算两列的相关性
df.stat.corr("Quantity", "UnitPrice")
df.select(corr("Quantity", "UnitPrice")).show()

# describe 计算一列或一组列的汇总统计结果，它会计算所有数值型列的计数，平均值，标准差，最小值和最大值
df.describe().show()

#更多统计函数封装在 StatFunction中，例如approxQuantile
```

* 处理字符串类型


```scala
// initcap 函数会将给定字符串中空格分隔的每个单词首字母大写
import org.apache.spark.sql.functions.initcap
df.select(initcap(col("Description"))).show(2, false)

// lower和upper 将在字符串转换为小写或者大写
import org.apache.spark.sql.functions.{lower, upper}
df.select(col("Description"), lower(col("Description")), upper(lower(col("Description")))).show(2)
// 删除字符串周围的空格或者在其周围添加空格，可以使用 lpad、ltrim、rpad、rtrim、trim来实现
import org.apache.spark.sql.functions.{lit, ltrim, rtrim, rpad, lpad, trim}
df.select(
  ltrim(lit("   HELLO   ")).alias("ltrim"),
  rtrim(lit("   HELLO   ")).alias("rtrim"),
  trim(lit("   HELLO   ")).as("trim"),
  lpad(lit("HELLO"), 3, " ").alias("lp"),
  rpad(lit("HELLO"), 3, " ").alias("rp")
).show()
```

```py
# in Python

# initcap 函数会将给定字符串中空格分隔的每个单词首字母大写
from pyspark.sql.functions import initcap
df.select(initcap(col("Description"))).show()

# lower和upper 将在字符串转换为小写或者大写
from pyspark.sql.functions import lower, upper
df.select(col("Description"), lower(col("Description")), upper(lower(col("Description")))).show(2)

#删除字符串周围的空格或者在其周围添加空格，可以使用 lpad、ltrim、rpad、rtrim、trim来实现
from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim
df.select(
  ltrim(lit("   HELLO   ")).alias("ltrim"),
  rtrim(lit("   HELLO   ")).alias("rtrim"),
  trim(lit("   HELLO   ")).as("trim"),
  lpad(lit("HELLO"), 3, " ").alias("lp"),
  rpad(lit("HELLO"), 3, " ").alias("rp")
).show()
```
```